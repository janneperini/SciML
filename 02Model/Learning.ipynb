{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# U-Net Architecture\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Define encoder layers\n",
    "        self.enc1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.enc2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.enc3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        # Define decoder layers\n",
    "        self.dec1 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.dec2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=1)  # Output single-channel heatmap\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.enc1(x))\n",
    "        x2 = F.relu(self.enc2(F.max_pool2d(x1, 2)))\n",
    "        x3 = F.relu(self.enc3(F.max_pool2d(x2, 2)))\n",
    "        \n",
    "        # Decoder\n",
    "        x = F.relu(self.dec1(F.interpolate(x3, scale_factor=2, mode='bilinear', align_corners=True)))\n",
    "        x = F.relu(self.dec2(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)))\n",
    "        \n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model (only run once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find image file by ID\n",
    "def find_image_path(directory, prefix, image_id):\n",
    "    path = os.path.join(directory, f\"{prefix}_id{image_id}.png\")\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "# Custom Dataset class for Satellite and Heatmap images\n",
    "class SatelliteHeatmapDataset(Dataset):\n",
    "    def __init__(self, satellite_dir, heatmap_dir, transform=None):\n",
    "        self.satellite_dir = satellite_dir\n",
    "        self.heatmap_dir = heatmap_dir\n",
    "        self.transform = transform\n",
    "        self.satellite_ids = [os.path.splitext(f)[0].split('_id')[-1] \n",
    "                              for f in os.listdir(satellite_dir) if os.path.isfile(os.path.join(satellite_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.satellite_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.satellite_ids[idx]\n",
    "        satellite_path = find_image_path(self.satellite_dir, \"satellite\", image_id)\n",
    "        heatmap_path = find_image_path(self.heatmap_dir, \"heatmap\", image_id)\n",
    "        if satellite_path is None or heatmap_path is None:\n",
    "            print(f\"File not found: {satellite_path} or {heatmap_path}\")\n",
    "            return None\n",
    "        satellite_image = Image.open(satellite_path)\n",
    "        heatmap_image = Image.open(heatmap_path)\n",
    "        if self.transform:\n",
    "            satellite_image = self.transform(satellite_image)\n",
    "            heatmap_image = self.transform(heatmap_image)\n",
    "        return satellite_image, heatmap_image\n",
    "\n",
    "# Custom collate function to filter out None values\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if len(batch) == 0:\n",
    "        return torch.empty(0), torch.empty(0)\n",
    "    return torch.utils.data.default_collate(batch)\n",
    "\n",
    "# Directories containing satellite and heatmap images\n",
    "satellite_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Satellite'\n",
    "heatmap_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Heatmap'\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = SatelliteHeatmapDataset(satellite_dir, heatmap_dir, transform=transform)\n",
    "\n",
    "# Split the IDs into training and validation sets\n",
    "train_ids, val_ids = train_test_split(dataset.satellite_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "class SplitSatelliteHeatmapDataset(Dataset):\n",
    "    def __init__(self, satellite_dir, heatmap_dir, ids, transform=None):\n",
    "        self.satellite_dir = satellite_dir\n",
    "        self.heatmap_dir = heatmap_dir\n",
    "        self.transform = transform\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.ids[idx]\n",
    "        satellite_path = find_image_path(self.satellite_dir, \"satellite\", image_id)\n",
    "        heatmap_path = find_image_path(self.heatmap_dir, \"heatmap\", image_id)\n",
    "        if satellite_path is None or heatmap_path is None:\n",
    "            print(f\"File not found: {satellite_path} or {heatmap_path}\")\n",
    "            return None\n",
    "        satellite_image = Image.open(satellite_path)\n",
    "        heatmap_image = Image.open(heatmap_path)\n",
    "        if self.transform:\n",
    "            satellite_image = self.transform(satellite_image)\n",
    "            heatmap_image = self.transform(heatmap_image)\n",
    "        return satellite_image, heatmap_image\n",
    "\n",
    "# Create separate datasets\n",
    "train_dataset = SplitSatelliteHeatmapDataset(satellite_dir, heatmap_dir, train_ids, transform=transform)\n",
    "val_dataset = SplitSatelliteHeatmapDataset(satellite_dir, heatmap_dir, val_ids, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize model\n",
    "model = UNet()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop with graceful KeyboardInterrupt handling\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set model to training mode\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for satellite_images, heatmap_images in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(satellite_images)\n",
    "                loss = criterion(outputs, heatmap_images)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            val_loss = evaluate_model(model, val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted! Plotting current progress...\")\n",
    "\n",
    "    # Plot the training and validation loss even if interrupted\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for satellite_images, heatmap_images in val_loader:\n",
    "            outputs = model(satellite_images)\n",
    "            loss = criterion(outputs, heatmap_images)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, num_epochs=20)\n",
    "torch.save(model.state_dict(), \"03TrainedModel/satellite_to_heatmap_unet.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/bgygmh4x281cznmrp1yt_r1h0000gn/T/ipykernel_72052/1264513119.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"03TrainedModel/satellite_to_heatmap_unet.pth\"))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '03TrainedModel/satellite_to_heatmap_unet.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m UNet()\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m03TrainedModel/satellite_to_heatmap_unet.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Directories\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '03TrainedModel/satellite_to_heatmap_unet.pth'"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load(\"03TrainedModel/satellite_to_heatmap_unet.pth\"))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Directories\n",
    "output_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Prediction'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the same transformations used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Function to predict and display heatmap for a random satellite image\n",
    "def predict_and_display_heatmap(model, satellite_dir, heatmap_dir, output_dir, transform):\n",
    "    satellite_files = os.listdir(satellite_dir)\n",
    "    random_file = random.choice(satellite_files)\n",
    "    \n",
    "    # Load and transform the satellite image\n",
    "    satellite_image_path = os.path.join(satellite_dir, random_file)\n",
    "    satellite_image = Image.open(satellite_image_path)\n",
    "    satellite_tensor = transform(satellite_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Load the corresponding training heatmap\n",
    "    heatmap_image_path = os.path.join(heatmap_dir, random_file.replace(\"satellite\", \"heatmap\"))\n",
    "    heatmap_image = Image.open(heatmap_image_path)\n",
    "\n",
    "    # Predict the heatmap\n",
    "    with torch.no_grad():\n",
    "        predicted_heatmap = model(satellite_tensor)\n",
    "\n",
    "    # Remove batch dimension and convert to numpy\n",
    "    predicted_heatmap = predicted_heatmap.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Save the predicted heatmap\n",
    "    output_file = random_file.replace(\"satellite\", \"prediction\")\n",
    "    output_path = os.path.join(output_dir, output_file)\n",
    "    save_image(torch.tensor(predicted_heatmap).unsqueeze(0), output_path)\n",
    "    print(f\"Predicted heatmap saved to {output_path}\")\n",
    "\n",
    "    # Display the satellite image, training heatmap, and predicted heatmap\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(satellite_image)\n",
    "    plt.title(\"Satellite Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap_image)\n",
    "    plt.title(\"Training Heatmap\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_heatmap, cmap='viridis')\n",
    "    plt.title(\"Predicted Heatmap\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Run the prediction and display\n",
    "predict_and_display_heatmap(model, satellite_dir, heatmap_dir, output_dir, transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
