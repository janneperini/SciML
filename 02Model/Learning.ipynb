{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find image file by ID\n",
    "def find_image_path(directory, prefix, image_id):\n",
    "    path = os.path.join(directory, f\"{prefix}_id{image_id}.png\")\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "# Custom Dataset class for Satellite and Heatmap images\n",
    "class SatelliteHeatmapDataset(Dataset):\n",
    "    def __init__(self, satellite_dir, heatmap_dir, transform=None):\n",
    "        self.satellite_dir = satellite_dir\n",
    "        self.heatmap_dir = heatmap_dir\n",
    "        self.transform = transform\n",
    "        self.satellite_ids = [os.path.splitext(f)[0].split('_id')[-1] \n",
    "                              for f in os.listdir(satellite_dir) if os.path.isfile(os.path.join(satellite_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.satellite_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.satellite_ids[idx]\n",
    "        satellite_path = find_image_path(self.satellite_dir, \"satellite\", image_id)\n",
    "        heatmap_path = find_image_path(self.heatmap_dir, \"heatmap\", image_id)\n",
    "        if satellite_path is None or heatmap_path is None:\n",
    "            print(f\"File not found: {satellite_path} or {heatmap_path}\")\n",
    "            return None\n",
    "        satellite_image = Image.open(satellite_path)\n",
    "        heatmap_image = Image.open(heatmap_path)\n",
    "        if self.transform:\n",
    "            satellite_image = self.transform(satellite_image)\n",
    "            heatmap_image = self.transform(heatmap_image)\n",
    "        return satellite_image, heatmap_image\n",
    "\n",
    "# Custom collate function to filter out None values\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if len(batch) == 0:\n",
    "        return torch.empty(0), torch.empty(0)\n",
    "    return torch.utils.data.default_collate(batch)\n",
    "\n",
    "# Directories containing satellite and heatmap images\n",
    "satellite_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Satellite'\n",
    "heatmap_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Heatmap'\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = SatelliteHeatmapDataset(satellite_dir, heatmap_dir, transform=transform)\n",
    "\n",
    "# Split the IDs into training and validation sets\n",
    "train_ids, val_ids = train_test_split(dataset.satellite_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "class SplitSatelliteHeatmapDataset(Dataset):\n",
    "    def __init__(self, satellite_dir, heatmap_dir, ids, transform=None):\n",
    "        self.satellite_dir = satellite_dir\n",
    "        self.heatmap_dir = heatmap_dir\n",
    "        self.transform = transform\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.ids[idx]\n",
    "        satellite_path = find_image_path(self.satellite_dir, \"satellite\", image_id)\n",
    "        heatmap_path = find_image_path(self.heatmap_dir, \"heatmap\", image_id)\n",
    "        if satellite_path is None or heatmap_path is None:\n",
    "            print(f\"File not found: {satellite_path} or {heatmap_path}\")\n",
    "            return None\n",
    "        satellite_image = Image.open(satellite_path)\n",
    "        heatmap_image = Image.open(heatmap_path)\n",
    "        if self.transform:\n",
    "            satellite_image = self.transform(satellite_image)\n",
    "            heatmap_image = self.transform(heatmap_image)\n",
    "        return satellite_image, heatmap_image\n",
    "\n",
    "# Create separate datasets\n",
    "train_dataset = SplitSatelliteHeatmapDataset(satellite_dir, heatmap_dir, train_ids, transform=transform)\n",
    "val_dataset = SplitSatelliteHeatmapDataset(satellite_dir, heatmap_dir, val_ids, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# U-Net Architecture\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Define encoder layers\n",
    "        self.enc1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.enc2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.enc3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        # Define decoder layers\n",
    "        self.dec1 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.dec2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=1)  # Output single-channel heatmap\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.enc1(x))\n",
    "        x2 = F.relu(self.enc2(F.max_pool2d(x1, 2)))\n",
    "        x3 = F.relu(self.enc3(F.max_pool2d(x2, 2)))\n",
    "        \n",
    "        # Decoder\n",
    "        x = F.relu(self.dec1(F.interpolate(x3, scale_factor=2, mode='bilinear', align_corners=True)))\n",
    "        x = F.relu(self.dec2(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)))\n",
    "        \n",
    "        return self.final(x)\n",
    "\n",
    "# Initialize model\n",
    "model = UNet()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop with graceful KeyboardInterrupt handling\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set model to training mode\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for satellite_images, heatmap_images in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(satellite_images)\n",
    "                loss = criterion(outputs, heatmap_images)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            val_loss = evaluate_model(model, val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted! Plotting current progress...\")\n",
    "\n",
    "    # Plot the training and validation loss even if interrupted\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for satellite_images, heatmap_images in val_loader:\n",
    "            outputs = model(satellite_images)\n",
    "            loss = criterion(outputs, heatmap_images)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader, num_epochs=20)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), \"satellite_to_heatmap_unet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load(\"satellite_to_heatmap_unet.pth\"))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Directories\n",
    "satellite_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Satellite'\n",
    "heatmap_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Heatmap'\n",
    "output_dir = '/Users/janne/Library/CloudStorage/OneDrive-ETHZurich/ML_Shared/Images/Prediction'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the same transformations used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Function to predict and display heatmap for a random satellite image\n",
    "def predict_and_display_heatmap(model, satellite_dir, heatmap_dir, output_dir, transform):\n",
    "    satellite_files = os.listdir(satellite_dir)\n",
    "    random_file = random.choice(satellite_files)\n",
    "    \n",
    "    # Load and transform the satellite image\n",
    "    satellite_image_path = os.path.join(satellite_dir, random_file)\n",
    "    satellite_image = Image.open(satellite_image_path)\n",
    "    satellite_tensor = transform(satellite_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Load the corresponding training heatmap\n",
    "    heatmap_image_path = os.path.join(heatmap_dir, random_file.replace(\"satellite\", \"heatmap\"))\n",
    "    heatmap_image = Image.open(heatmap_image_path)\n",
    "\n",
    "    # Predict the heatmap\n",
    "    with torch.no_grad():\n",
    "        predicted_heatmap = model(satellite_tensor)\n",
    "\n",
    "    # Remove batch dimension and convert to numpy\n",
    "    predicted_heatmap = predicted_heatmap.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Save the predicted heatmap\n",
    "    output_file = random_file.replace(\"satellite\", \"prediction\")\n",
    "    output_path = os.path.join(output_dir, output_file)\n",
    "    save_image(torch.tensor(predicted_heatmap).unsqueeze(0), output_path)\n",
    "    print(f\"Predicted heatmap saved to {output_path}\")\n",
    "\n",
    "    # Display the satellite image, training heatmap, and predicted heatmap\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(satellite_image)\n",
    "    plt.title(\"Satellite Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap_image)\n",
    "    plt.title(\"Training Heatmap\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_heatmap, cmap='viridis')  # Use 'viridis' colormap for heatmap\n",
    "    plt.title(\"Predicted Heatmap\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Run the prediction and display\n",
    "predict_and_display_heatmap(model, satellite_dir, heatmap_dir, output_dir, transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
